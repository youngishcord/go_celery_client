# Простой клиент Celery на Go

Используется только библиотека для связи с RabbitMQ `amqp091-go`, остальное реализовано с нуля.

Вопросы, на которые еще предстоит ответить:
- [ ] Как работать с цепочкой сообщений?
- [ ] Как реализовать ограничение по количеству чтений сообщений из очереди?
- [ ] Надо разобраться с `exchange` в rabbit.
- [ ] Нормальное хранение функций, та еще задача...

В планах разработка:
- [ ] Нормальная структура клиента с интерфейсами, которые можно подменять для смены бекенда "RPC" на Redis и наоборот.
- [ ] Нормальный роутинг задач в разные горутины.
- [ ] Метаданные о задаче лежат в ее хедере в формате мапы. Их скорее всего надо распарсить вручную в структуру, чтобы было проще потом работать с этими данными. Но не займет ли это очень много времени? Как было бы оптимальнее?

В планах фичи:
- [ ] Получение сообщений от RabbitMQ.
- [ ] Ответ на сообщения в RabbitMQ через RPC.
- [ ] Ответ на сообщения через Redis.
- [ ] Работа с цепочкой задач.
- [ ] Реализовать heartbeat от воркера.
- [ ] Работа с chord
- [ ] Работа с group
- [ ] Работа с map
- [ ] Работа с chunk

# Заметки по реализации

## Все работает через интерфейсы?

Получается так, что все компоненты работают через интерфейсы. Брокер и бекенд подменяемы, и задачи, 
которые через них получаются, тоже должны работать через интерфейсы, поскольку имеют разный 
набор вспомогательных параметров.  

## Rpc backend в celery

При работе с rpc backend при отправке задачи в очередь publisher создает для 
результата отдельную очередь, которая скорее всего исчезает после какого то времени, 
но я не могу это проверить, поскольку дефолтное значение очень велико. Можно отдельно настроить
время жизни очереди, но это делается в Celery. Сейчас основная задача, поработать с Redis.

## Rabbit сам определяет слушателя, которому поступает задача

По всей видимости RabbitMQ сам определяет получателя сообщения по принципу roundrobin. Но я точно 
читал, что каждый воркер может резервировать на себя только определенное количество задач, а 
остальные остаются в свободном пуле. Надо это проверить.

Да каждый воркер имеет у себя параметр для резервирования количества задач, и этот параметр относится к 
каналу подключения консюмера. Тоесть его можно настроить для каждого воркера отдельно.

Ниже приведен пример настройки, при котором резервируется 2 сообщения напрямую для Rabbit в Go
``` Go
err = ch.Qos(
    2,     // prefetch count
    0,     // prefetch size (0 means unlimited)
    false, // global (false = per consumer, true = per channel)
)
```

## Переотправка сообщения

Если по какой то причине необходимо вернуть сообщение в пул очереди, можно использовать метод `Nack`, который 
вернет задачу в очередь нетронутой. Это удобно, если у воркера, например, нет функции для исполнения полученной задачи.
``` Go
if header.Task != "test" {
    err = message.Nack(false, true)
    if err != nil {
        log.Fatalln(err)
    } else {
        fmt.Println("task nack")
    }
}
```

## Тесты на работоспособность цепочек

Воркер должен реализовывать передачу задачи по цепочке, что накладывает ответственность по работе с обработкой 
вложенных данных о цепочке. Воркер должен передавать результат корректно в зависимости от полученных параметров
и встраивать их внутрь args и kwargs. Нужно посмотреть, как именно это работает и реализовать подобное поведение.

При передаче результата по цепочке результат является первым параметром и должен передаваться в массив
на первую позицию.

Это происходит в воркере или в клиенте???

В Celery возврат args и kwargs в 

# Ссылки

- Протокол сообщений Celery https://docs.celeryq.dev/en/latest/internals/protocol.html 

